{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**AI & Machine Learning (KAN-CINTO4003U) - Copenhagen Business School | Spring 2025**\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Part III: LLM\n",
    "\n",
    "Please see the description of the assignment in the README file (section 3) <br>\n",
    "**Guide notebook**: [guides/llm_guide.ipynb](guides/llm_guide.ipynb)\n",
    "\n",
    "\n",
    "***\n",
    "\n",
    "<br>\n",
    "\n",
    "* Note that you should report results using a classification report. \n",
    "\n",
    "* Also, remember to include some reflections on your results: how do they compare with the results from Part I, BoW?, and part II, BERT? Are there any hyperparameters or prompting techniques that are particularly important?\n",
    "\n",
    "* You should follow the steps given in the `llm_guide` notebook\n",
    "\n",
    "<br>\n",
    "\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports for the project\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load the data\n",
    "\n",
    "We can load this data directly from [Hugging Face Datasets](https://huggingface.co/docs/datasets/) - The HuggingFace Hub- into a Pandas DataFrame. Pretty neat!\n",
    "\n",
    "**Note**: This cell will download the dataset and keep it in memory. If you run this cell multiple times, it will download the dataset multiple times.\n",
    "\n",
    "You are welcome to increase the `frac` parameter to load more data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "splits = {'train': 'data/train-00000-of-00001.parquet', 'test': 'data/test-00000-of-00001.parquet'}\n",
    "# train = pd.read_parquet(\"hf://datasets/fancyzhx/ag_news/\" + splits[\"train\"])\n",
    "test = pd.read_parquet(\"hf://datasets/fancyzhx/ag_news/\" + splits[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((760, 2),)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_map = {\n",
    "    0: 'World',\n",
    "    1: 'Sports',\n",
    "    2: 'Business',\n",
    "    3: 'Sci/Tech'\n",
    "}\n",
    "\n",
    "def preprocess(df: pd.DataFrame, frac = 1e-2, label_map = label_map, seed=42) -> pd.DataFrame:\n",
    "    return  (\n",
    "        df\n",
    "        .assign(label=lambda x: x['label'].map(label_map))\n",
    "        [lambda df: df['label'].isin(label_map.values())]\n",
    "        .groupby('label')\n",
    "        .apply(lambda x: x.sample(frac=frac, random_state=seed))\n",
    "        .reset_index(drop=True)\n",
    "\n",
    "    )\n",
    "\n",
    "# train_df = preprocess(train, frac=0.01)\n",
    "test_df = preprocess(test, frac=0.1)\n",
    "\n",
    "# clear up some memory by deleting the original dataframes\n",
    "# del train\n",
    "del test\n",
    "\n",
    "test_df.shape, # train_df.shape, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from decouple import Config, RepositoryEnv\n",
    "from ibm_watsonx_ai import APIClient\n",
    "from ibm_watsonx_ai import Credentials\n",
    "from ibm_watsonx_ai.foundation_models import ModelInference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the environment variables using python-decouple\n",
    "# The .env file should be in the root of the project\n",
    "# The .env file should NOT be committed to the repository\n",
    "\n",
    "config = Config(RepositoryEnv(\".env.myapikey\"))\n",
    "\n",
    "# Load the credentials\n",
    "WX_API_KEY = config(\"WX_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "credentials = Credentials(\n",
    "    url = \"https://us-south.ml.cloud.ibm.com\",\n",
    "    api_key = WX_API_KEY\n",
    ")\n",
    "\n",
    "client = APIClient(\n",
    "    credentials=credentials, \n",
    "    project_id=\"8b2fe967-dfcc-4e5c-ae77-ac79a96ed699\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failure during Get available foundation models. (GET https://us-south.ml.cloud.ibm.com/ml/v1/foundation_model_specs?version=2025-02-19&project_id=8b2fe967-dfcc-4e5c-ae77-ac79a96ed699&filters=function_text_generation%2C%21lifecycle_withdrawn%3Aand&limit=200)\n",
      "Status code: 403, body: {\"errors\":[{\"code\":\"no_associated_service_instance_error\",\"message\":\"project_id 8b2fe967-dfcc-4e5c-ae77-ac79a96ed699 is not associated with a WML instance\",\"more_info\":\"https://cloud.ibm.com/apidocs/watsonx-ai\"}],\"trace\":\"cd1144cc6543d2fa69ad742531f794cc\",\"status_code\":403}\n",
      "Unable to get model specifications from url: https://us-south.ml.cloud.ibm.com\n",
      "Reason: Failure during Get available foundation models. (GET https://us-south.ml.cloud.ibm.com/ml/v1/foundation_model_specs?version=2025-02-19&project_id=8b2fe967-dfcc-4e5c-ae77-ac79a96ed699&filters=function_text_generation%2C%21lifecycle_withdrawn%3Aand&limit=200)\n",
      "Status code: 403, body: {\"errors\":[{\"code\":\"no_associated_service_instance_error\",\"message\":\"project_id 8b2fe967-dfcc-4e5c-ae77-ac79a96ed699 is not associated with a WML instance\",\"more_info\":\"https://cloud.ibm.com/apidocs/watsonx-ai\"}],\"trace\":\"cd1144cc6543d2fa69ad742531f794cc\",\"status_code\":403}\n"
     ]
    },
    {
     "ename": "WMLClientError",
     "evalue": "Unable to get model specifications from url: https://us-south.ml.cloud.ibm.com\nReason: Failure during Get available foundation models. (GET https://us-south.ml.cloud.ibm.com/ml/v1/foundation_model_specs?version=2025-02-19&project_id=8b2fe967-dfcc-4e5c-ae77-ac79a96ed699&filters=function_text_generation%2C%21lifecycle_withdrawn%3Aand&limit=200)\nStatus code: 403, body: {\"errors\":[{\"code\":\"no_associated_service_instance_error\",\"message\":\"project_id 8b2fe967-dfcc-4e5c-ae77-ac79a96ed699 is not associated with a WML instance\",\"more_info\":\"https://cloud.ibm.com/apidocs/watsonx-ai\"}],\"trace\":\"cd1144cc6543d2fa69ad742531f794cc\",\"status_code\":403}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mApiRequestFailure\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Paul Wegner\\anaconda3\\envs\\aiml25-ma2\\Lib\\site-packages\\ibm_watsonx_ai\\foundation_models_manager.py:94\u001b[39m, in \u001b[36mFoundationModelsManager._get_spec\u001b[39m\u001b[34m(self, url, operation_name, error_msg_id, model_id, limit, filters, asynchronous, get_all, tech_preview)\u001b[39m\n\u001b[32m     93\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m94\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_with_or_without_limit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     95\u001b[39m \u001b[43m            \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     96\u001b[39m \u001b[43m            \u001b[49m\u001b[43mlimit\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlimit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     97\u001b[39m \u001b[43m            \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43moperation_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     98\u001b[39m \u001b[43m            \u001b[49m\u001b[43mquery_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     99\u001b[39m \u001b[43m            \u001b[49m\u001b[43m_async\u001b[49m\u001b[43m=\u001b[49m\u001b[43masynchronous\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    100\u001b[39m \u001b[43m            \u001b[49m\u001b[43m_all\u001b[49m\u001b[43m=\u001b[49m\u001b[43mget_all\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    101\u001b[39m \u001b[43m            \u001b[49m\u001b[43mskip_space_project_chk\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    102\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    103\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m WMLClientError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Paul Wegner\\anaconda3\\envs\\aiml25-ma2\\Lib\\site-packages\\ibm_watsonx_ai\\wml_resource.py:509\u001b[39m, in \u001b[36mWMLResource._get_with_or_without_limit\u001b[39m\u001b[34m(self, url, limit, op_name, summary, pre_defined, revision, skip_space_project_chk, query_params, _async, _all, _filter_func)\u001b[39m\n\u001b[32m    505\u001b[39m response_get = requests.get(\n\u001b[32m    506\u001b[39m     url, headers=\u001b[38;5;28mself\u001b[39m._client._get_headers(), params=params\n\u001b[32m    507\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m509\u001b[39m result = cast(\u001b[38;5;28mdict\u001b[39m, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_handle_response\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m200\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_get\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    510\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mresources\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m result:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Paul Wegner\\anaconda3\\envs\\aiml25-ma2\\Lib\\site-packages\\ibm_watsonx_ai\\wml_resource.py:157\u001b[39m, in \u001b[36mWMLResource._handle_response\u001b[39m\u001b[34m(self, expected_status_code, operationName, response, json_response, _silent_response_logging, _field_to_hide)\u001b[39m\n\u001b[32m    156\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m157\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m ApiRequestFailure(\n\u001b[32m    158\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mFailure during \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m.format(operationName),\n\u001b[32m    159\u001b[39m         response,\n\u001b[32m    160\u001b[39m     )\n",
      "\u001b[31mApiRequestFailure\u001b[39m: Failure during Get available foundation models. (GET https://us-south.ml.cloud.ibm.com/ml/v1/foundation_model_specs?version=2025-02-19&project_id=8b2fe967-dfcc-4e5c-ae77-ac79a96ed699&filters=function_text_generation%2C%21lifecycle_withdrawn%3Aand&limit=200)\nStatus code: 403, body: {\"errors\":[{\"code\":\"no_associated_service_instance_error\",\"message\":\"project_id 8b2fe967-dfcc-4e5c-ae77-ac79a96ed699 is not associated with a WML instance\",\"more_info\":\"https://cloud.ibm.com/apidocs/watsonx-ai\"}],\"trace\":\"cd1144cc6543d2fa69ad742531f794cc\",\"status_code\":403}",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mWMLClientError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m model = \u001b[43mModelInference\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[43mapi_client\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mibm/granite-13b-instruct-v2\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Paul Wegner\\anaconda3\\envs\\aiml25-ma2\\Lib\\site-packages\\ibm_watsonx_ai\\foundation_models\\inference\\model_inference.py:201\u001b[39m, in \u001b[36mModelInference.__init__\u001b[39m\u001b[34m(self, model_id, deployment_id, params, credentials, project_id, space_id, verify, api_client, validate, persistent_connection)\u001b[39m\n\u001b[32m    199\u001b[39m \u001b[38;5;28mself\u001b[39m._inference: BaseModelInference\n\u001b[32m    200\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.model_id:\n\u001b[32m--> \u001b[39m\u001b[32m201\u001b[39m     \u001b[38;5;28mself\u001b[39m._inference = \u001b[43mFMModelInference\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    202\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    203\u001b[39m \u001b[43m        \u001b[49m\u001b[43mapi_client\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_client\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    204\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    205\u001b[39m \u001b[43m        \u001b[49m\u001b[43mvalidate\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvalidate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    206\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpersistent_connection\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpersistent_connection\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    207\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    208\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    209\u001b[39m     \u001b[38;5;28mself\u001b[39m.deployment_id = cast(\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mself\u001b[39m.deployment_id)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Paul Wegner\\anaconda3\\envs\\aiml25-ma2\\Lib\\site-packages\\ibm_watsonx_ai\\foundation_models\\inference\\fm_model_inference.py:69\u001b[39m, in \u001b[36mFMModelInference.__init__\u001b[39m\u001b[34m(self, model_id, api_client, params, validate, persistent_connection)\u001b[39m\n\u001b[32m     66\u001b[39m model_specs: \u001b[38;5;28mdict\u001b[39m = \u001b[38;5;28mdict\u001b[39m()\n\u001b[32m     68\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._client._use_fm_ga_api:\n\u001b[32m---> \u001b[39m\u001b[32m69\u001b[39m     model_specs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfoundation_models\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_model_specs\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[assignment]\u001b[39;00m\n\u001b[32m     70\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     71\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m catch_warnings():\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Paul Wegner\\anaconda3\\envs\\aiml25-ma2\\Lib\\site-packages\\ibm_watsonx_ai\\foundation_models_manager.py:148\u001b[39m, in \u001b[36mFoundationModelsManager.get_model_specs\u001b[39m\u001b[34m(self, model_id, limit, asynchronous, get_all, **kwargs)\u001b[39m\n\u001b[32m    112\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_model_specs\u001b[39m(\n\u001b[32m    113\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    114\u001b[39m     model_id: \u001b[38;5;28mstr\u001b[39m | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    118\u001b[39m     **kwargs: Any,\n\u001b[32m    119\u001b[39m ) -> \u001b[38;5;28mdict\u001b[39m | Generator | \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    120\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    121\u001b[39m \u001b[33;03m    Retrieves a list of specifications for a deployed foundation model.\u001b[39;00m\n\u001b[32m    122\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    146\u001b[39m \u001b[33;03m        client.foundation_models.get_model_specs(model_id=\"google/flan-ul2\")\u001b[39;00m\n\u001b[32m    147\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m148\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_spec\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    149\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mservice_instance\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_href_definitions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_fm_specifications_href\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    150\u001b[39m \u001b[43m        \u001b[49m\u001b[43moperation_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mGet available foundation models\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    151\u001b[39m \u001b[43m        \u001b[49m\u001b[43merror_msg_id\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfm_prompt_tuning_no_model_specs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    152\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfilters\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    153\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\n\u001b[32m    154\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCPD_version\u001b[49m\u001b[43m \u001b[49m\u001b[43m<\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m5.0\u001b[39;49m\n\u001b[32m    155\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunction_text_generation,!lifecycle_withdrawn:and\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m    156\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    157\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    158\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlimit\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlimit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    159\u001b[39m \u001b[43m        \u001b[49m\u001b[43masynchronous\u001b[49m\u001b[43m=\u001b[49m\u001b[43masynchronous\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    160\u001b[39m \u001b[43m        \u001b[49m\u001b[43mget_all\u001b[49m\u001b[43m=\u001b[49m\u001b[43mget_all\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    161\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtech_preview\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtech_preview\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    162\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Paul Wegner\\anaconda3\\envs\\aiml25-ma2\\Lib\\site-packages\\ibm_watsonx_ai\\foundation_models_manager.py:104\u001b[39m, in \u001b[36mFoundationModelsManager._get_spec\u001b[39m\u001b[34m(self, url, operation_name, error_msg_id, model_id, limit, filters, asynchronous, get_all, tech_preview)\u001b[39m\n\u001b[32m     94\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._get_with_or_without_limit(\n\u001b[32m     95\u001b[39m             url=url,\n\u001b[32m     96\u001b[39m             limit=limit,\n\u001b[32m   (...)\u001b[39m\u001b[32m    101\u001b[39m             skip_space_project_chk=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    102\u001b[39m         )\n\u001b[32m    103\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m WMLClientError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m--> \u001b[39m\u001b[32m104\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m WMLClientError(\n\u001b[32m    105\u001b[39m         Messages.get_message(\n\u001b[32m    106\u001b[39m             \u001b[38;5;28mself\u001b[39m._client.credentials.url,\n\u001b[32m    107\u001b[39m             message_id=error_msg_id,\n\u001b[32m    108\u001b[39m         ),\n\u001b[32m    109\u001b[39m         e,\n\u001b[32m    110\u001b[39m     )\n",
      "\u001b[31mWMLClientError\u001b[39m: Unable to get model specifications from url: https://us-south.ml.cloud.ibm.com\nReason: Failure during Get available foundation models. (GET https://us-south.ml.cloud.ibm.com/ml/v1/foundation_model_specs?version=2025-02-19&project_id=8b2fe967-dfcc-4e5c-ae77-ac79a96ed699&filters=function_text_generation%2C%21lifecycle_withdrawn%3Aand&limit=200)\nStatus code: 403, body: {\"errors\":[{\"code\":\"no_associated_service_instance_error\",\"message\":\"project_id 8b2fe967-dfcc-4e5c-ae77-ac79a96ed699 is not associated with a WML instance\",\"more_info\":\"https://cloud.ibm.com/apidocs/watsonx-ai\"}],\"trace\":\"cd1144cc6543d2fa69ad742531f794cc\",\"status_code\":403}"
     ]
    }
   ],
   "source": [
    "# Unfortunately, the connection to the ML Service seems to be broken which is blocking me from running the code below. To be validated once the connection is back up.\n",
    "\n",
    "model = ModelInference(\n",
    "    api_client=client,\n",
    "    model_id=\"ibm/granite-13b-instruct-v2\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ibm_watsonx_ai.foundation_models.schema import TextGenParameters\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report \n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = {'train': 'data/train-00000-of-00001.parquet', 'test': 'data/test-00000-of-00001.parquet'}\n",
    "# train = pd.read_parquet(\"hf://datasets/fancyzhx/ag_news/\" + splits[\"train\"])\n",
    "test = pd.read_parquet(\"hf://datasets/fancyzhx/ag_news/\" + splits[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = {\n",
    "    0: 'World',\n",
    "    1: 'Sports',\n",
    "    2: 'Business',\n",
    "    3: 'Sci/Tech'\n",
    "}\n",
    "\n",
    "def preprocess(df: pd.DataFrame, frac : float = 1e-2, label_map : dict[int, str] = label_map, seed : int = 42) -> pd.DataFrame:\n",
    "    \"\"\" Preprocess the dataset \n",
    "\n",
    "    Operations:\n",
    "    - Map the label to the corresponding category\n",
    "    - Filter out the labels not in the label_map\n",
    "    - Sample a fraction of the dataset (stratified by label)\n",
    "\n",
    "    Args:\n",
    "    - df (pd.DataFrame): The dataset to preprocess\n",
    "    - frac (float): The fraction of the dataset to sample in each category\n",
    "    - label_map (dict): A mapping of the original label to the new label\n",
    "    - seed (int): The random seed for reproducibility\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: The preprocessed dataset\n",
    "    \"\"\"\n",
    "\n",
    "    return  (\n",
    "        df\n",
    "        .assign(label=lambda x: x['label'].map(label_map))\n",
    "        [lambda df: df['label'].isin(label_map.values())]\n",
    "        .groupby('label')[[\"text\", \"label\"]]\n",
    "        .apply(lambda x: x.sample(frac=frac, random_state=seed))\n",
    "        .reset_index(drop=True)\n",
    "\n",
    "    )\n",
    "\n",
    "# train_df = preprocess(train, frac=0.01)\n",
    "test_df = preprocess(test, frac=0.1)\n",
    "\n",
    "# clear up some memory by deleting the original dataframes\n",
    "# del train\n",
    "del test\n",
    "\n",
    "test_df.shape # , train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PARAMS = TextGenParameters(\n",
    "    temperature=0,              # Higher temperature means more randomness - In this case we don't want randomness\n",
    "    max_new_tokens=10,          # Maximum number of tokens to generate\n",
    "    stop_sequences=[\".\", \"\\n\"], # Stop generating text when these sequences are encountered\n",
    ")\n",
    "\n",
    "model = ModelInference(\n",
    "    api_client=client,\n",
    "    model_id=\"ibm/granite-13b-instruct-v2\",  # We could also try a larger model!\n",
    "    params=PARAMS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT = \"\"\"You task is to classify news stories into one of five categories\n",
    "\n",
    "CATEGORIES:\n",
    "{categories}\n",
    "\n",
    "TEXT:\n",
    "{text}\n",
    "\n",
    "Please assign the correct category to the text. Answer with the correct category and nothing else.\n",
    "\n",
    "Category:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CATEGORIES = \"- \" + \"\\n- \".join(test_df[\"label\"].unique())  # Create a string with all categories\n",
    "\n",
    "predictions = []\n",
    "\n",
    "for text in tqdm(test_df[\"text\"]):\n",
    "\n",
    "    # format the prompt with the categories and the text\n",
    "    prompt = SYSTEM_PROMPT.format(categories=CATEGORIES, text=text)\n",
    "    \n",
    "    # generate the response from the model\n",
    "    response = model.generate(prompt)\n",
    "\n",
    "    # extract the generated text from the response\n",
    "    prediction = response[\"results\"][0][\"generated_text\"].strip()\n",
    "\n",
    "    # append the prediction to the list of predictions\n",
    "    predictions.append(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(test_df.label, predictions))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiml25-ma2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
